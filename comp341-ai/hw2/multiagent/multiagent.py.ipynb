{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0995883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiAgents.py\n",
    "# --------------\n",
    "# Licensing Information:  You are free to use or extend these projects for\n",
    "# educational purposes provided that (1) you do not distribute or publish\n",
    "# solutions, (2) you retain this notice, and (3) you provide clear\n",
    "# attribution to UC Berkeley, including a link to http://ai.berkeley.edu.\n",
    "# \n",
    "# Attribution Information: The Pacman AI projects were developed at UC Berkeley.\n",
    "# The core projects and autograders were primarily created by John DeNero\n",
    "# (denero@cs.berkeley.edu) and Dan Klein (klein@cs.berkeley.edu).\n",
    "# Student side autograding was added by Brad Miller, Nick Hay, and\n",
    "# Pieter Abbeel (pabbeel@cs.berkeley.edu).\n",
    "\n",
    "\n",
    "from util import manhattanDistance\n",
    "from game import Directions\n",
    "import random, util\n",
    "\n",
    "from game import Agent\n",
    "\n",
    "class ReflexAgent(Agent):\n",
    "    \"\"\"\n",
    "      A reflex agent chooses an action at each choice point by examining\n",
    "      its alternatives via a state evaluation function.\n",
    "\n",
    "      The code below is provided as a guide.  You are welcome to change\n",
    "      it in any way you see fit, so long as you don't touch our method\n",
    "      headers.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def getAction(self, gameState):\n",
    "        \"\"\"\n",
    "        You do not need to change this method, but you're welcome to.\n",
    "\n",
    "        getAction chooses among the best options according to the evaluation function.\n",
    "\n",
    "        Just like in the previous project, getAction takes a GameState and returns\n",
    "        some Directions.X for some X in the set {North, South, West, East, Stop}\n",
    "        \"\"\"\n",
    "        # Collect legal moves and successor states\n",
    "        legalMoves = gameState.getLegalActions()\n",
    "        legalMoves.remove('Stop')\n",
    "\n",
    "        # Choose one of the best actions\n",
    "        scores = [self.evaluationFunction(gameState, action) for action in legalMoves]\n",
    "        bestScore = max(scores)\n",
    "        bestIndices = [index for index in range(len(scores)) if scores[index] == bestScore]\n",
    "        chosenIndex = random.choice(bestIndices) # Pick randomly among the best\n",
    "\n",
    "        \"Add more of your code here if you want to\"\n",
    "\n",
    "        return legalMoves[chosenIndex]\n",
    "\n",
    "    def evaluationFunction(self, currentGameState, action):\n",
    "        \"\"\"\n",
    "        Design a better evaluation function here.\n",
    "\n",
    "        The evaluation function takes in the current and proposed successor\n",
    "        GameStates (pacman.py) and returns a number, where higher numbers are better.\n",
    "\n",
    "        The code below extracts some useful information from the state, like the\n",
    "        remaining food (newFood) and Pacman position after moving (newPos).\n",
    "        newScaredTimes holds the number of moves that each ghost will remain\n",
    "        scared because of Pacman having eaten a power pellet.\n",
    "\n",
    "        Print out these variables to see what you're getting, then combine them\n",
    "        to create a masterful evaluation function.\n",
    "        \"\"\"\n",
    "        # Useful information you can extract from a GameState (pacman.py)\n",
    "        successorGameState = currentGameState.generatePacmanSuccessor(action)\n",
    "        newPos = successorGameState.getPacmanPosition()\n",
    "        newFood = successorGameState.getFood()\n",
    "        newGhostStates = successorGameState.getGhostStates()\n",
    "        newScaredTimes = [ghostState.scaredTimer for ghostState in newGhostStates]\n",
    "\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        score = float(0)\n",
    "        currentFood = currentGameState.getFood().asList()\n",
    "        x, y = newPos\n",
    "        \n",
    "        for m in range(len(newGhostStates)):\n",
    "            a, b = newGhostStates[m].getPosition()\n",
    "            movesAway = abs(x-a) + abs(y-b)\n",
    "            \n",
    "            \"Food is good\"\n",
    "            if newPos in currentFood:\n",
    "                score += 1\n",
    "                \n",
    "            \"Walls are bad\"\n",
    "            if currentGameState.hasWall(x, y):\n",
    "                score -= 2\n",
    "                \n",
    "            \"Eat ghost\"\n",
    "            if movesAway <= newScaredTimes[m]:\n",
    "                score += movesAway\n",
    "            \n",
    "            \"Run away\"\n",
    "            if movesAway < 2:\n",
    "                score -= 2\n",
    "            \n",
    "                \n",
    "            \"Add 1/minimum distance to nearest food\"\n",
    "            distanceToFood = []\n",
    "            for c, d in currentFood:\n",
    "                howFar = abs(x-c)\n",
    "                distanceToFood.append(howFar)\n",
    "            score -= 0.1 * min(distanceToFood)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        return score\n",
    "\n",
    "def scoreEvaluationFunction(currentGameState):\n",
    "    \"\"\"\n",
    "      This default evaluation function just returns the score of the state.\n",
    "      The score is the same one displayed in the Pacman GUI.\n",
    "\n",
    "      This evaluation function is meant for use with adversarial search agents\n",
    "      (not reflex agents).\n",
    "    \"\"\"\n",
    "    return currentGameState.getScore()\n",
    "\n",
    "class MultiAgentSearchAgent(Agent):\n",
    "    \"\"\"\n",
    "      This class provides some common elements to all of your\n",
    "      multi-agent searchers.  Any methods defined here will be available\n",
    "      to the MinimaxPacmanAgent, AlphaBetaPacmanAgent & ExpectimaxPacmanAgent.\n",
    "\n",
    "      You *do not* need to make any changes here, but you can if you want to\n",
    "      add functionality to all your adversarial search agents.  Please do not\n",
    "      remove anything, however.\n",
    "\n",
    "      Note: this is an abstract class: one that should not be instantiated.  It's\n",
    "      only partially specified, and designed to be extended.  Agent (game.py)\n",
    "      is another abstract class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, evalFn = 'scoreEvaluationFunction', depth = '2'):\n",
    "        self.index = 0 # Pacman is always agent index 0\n",
    "        self.evaluationFunction = util.lookup(evalFn, globals())\n",
    "        self.depth = int(depth)\n",
    "\n",
    "class MinimaxAgent(MultiAgentSearchAgent):\n",
    "    \"\"\"\n",
    "      Your minimax agent (question 2)\n",
    "    \"\"\"\n",
    "\n",
    "    def getAction(self, gameState):\n",
    "        \"\"\"\n",
    "          Returns the minimax action from the current gameState using self.depth\n",
    "          and self.evaluationFunction.\n",
    "\n",
    "          Here are some method calls that might be useful when implementing minimax.\n",
    "\n",
    "          gameState.getLegalActions(agentIndex):\n",
    "            Returns a list of legal actions for an agent\n",
    "            agentIndex=0 means Pacman, ghosts are >= 1\n",
    "\n",
    "          gameState.generateSuccessor(agentIndex, action):\n",
    "            Returns the successor game state after an agent takes an action\n",
    "\n",
    "          gameState.getNumAgents():\n",
    "            Returns the total number of agents in the game\n",
    "        \"\"\"\n",
    "        legal = gameState.getLegalActions(0)\n",
    "        successors = [gameState.generateSuccessor(0, action) for action in legal]\n",
    "        maxValue = -float('inf')\n",
    "        goalIndex = 0\n",
    "        for x in range(len(successors)):\n",
    "            actionValue = self.value(successors[x], 1, 0)\n",
    "            if actionValue > maxValue:\n",
    "                maxValue = actionValue\n",
    "                goalIndex = x\n",
    "        \n",
    "        return legal[goalIndex]\n",
    "        \n",
    "    def MAXvalue(self, gameState, agentIndex, depthSoFar):\n",
    "        legal = gameState.getLegalActions(agentIndex)\n",
    "        successors = [gameState.generateSuccessor(agentIndex, action) for action in legal]\n",
    "        x = -float('inf')\n",
    "        for successor in successors:\n",
    "            x = max(x, self.value(successor, 1, depthSoFar))\n",
    "        return x\n",
    "        \n",
    "    def MINvalue(self, gameState, agentIndex, depthSoFar):\n",
    "        legal = gameState.getLegalActions(agentIndex)\n",
    "        successors = [gameState.generateSuccessor(agentIndex, action) for action in legal]\n",
    "        x = float('inf')\n",
    "        for successor in successors:\n",
    "            if agentIndex + 1 == gameState.getNumAgents():\n",
    "                x = min(x, self.value(successor, 0, depthSoFar + 1))\n",
    "            else:\n",
    "                x = min(x, self.value(successor, agentIndex + 1, depthSoFar))\n",
    "        return x\n",
    "        \n",
    "    def value(self, gameState, agentIndex, depthSoFar):\n",
    "        \n",
    "        \"If requisite no. of searches complete, evaluation function\"\n",
    "        if depthSoFar == self.depth or gameState.isWin() or gameState.isLose():\n",
    "            return self.evaluationFunction(gameState)\n",
    "        \"If agentIndex is 0, perform MAX\"\n",
    "        if agentIndex == 0:\n",
    "            return self.MAXvalue(gameState, agentIndex, depthSoFar)\n",
    "        \"Else (if agentindex > 0), perform MIN\"\n",
    "        if agentIndex > 0:\n",
    "            return self.MINvalue(gameState, agentIndex, depthSoFar)\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "class AlphaBetaAgent(MultiAgentSearchAgent):\n",
    "    \"\"\"\n",
    "      Your minimax agent with alpha-beta pruning (question 3)\n",
    "    \"\"\"\n",
    "\n",
    "    def getAction(self, gameState):\n",
    "        \"\"\"\n",
    "          Returns the minimax action using self.depth and self.evaluationFunction\n",
    "        \"\"\"\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        alpha = -float('inf')\n",
    "        beta = float('inf')\n",
    "        legal = gameState.getLegalActions(0)\n",
    "        successors = [gameState.generateSuccessor(0, action) for action in legal]\n",
    "        maxValue = -float('inf')\n",
    "        goalIndex = 0\n",
    "        for x in range(len(successors)):\n",
    "            actionValue = self.value(successors[x], 1, 0, alpha, beta)\n",
    "            if actionValue > maxValue:\n",
    "                maxValue = actionValue\n",
    "                goalIndex = x\n",
    "                alpha = actionValue\n",
    "        \n",
    "        return legal[goalIndex]\n",
    "        \n",
    "    def MAXvalue(self, gameState, agentIndex, depthSoFar, alpha, beta):\n",
    "        legal = gameState.getLegalActions(agentIndex)\n",
    "        x = -float('inf')\n",
    "        for action in legal:\n",
    "            successor = gameState.generateSuccessor(agentIndex, action)\n",
    "            x = max(x, self.value(successor, 1, depthSoFar, alpha, beta))\n",
    "            if x > beta:\n",
    "                return x\n",
    "            alpha = max(alpha, x)\n",
    "        return x\n",
    "        \n",
    "    def MINvalue(self, gameState, agentIndex, depthSoFar, alpha, beta):\n",
    "        legal = gameState.getLegalActions(agentIndex)\n",
    "        x = float('inf')\n",
    "        for action in legal:\n",
    "            successor = gameState.generateSuccessor(agentIndex, action)\n",
    "            if agentIndex + 1 == gameState.getNumAgents():\n",
    "                x = min(x, self.value(successor, 0, depthSoFar + 1, alpha, beta))\n",
    "            else:\n",
    "                x = min(x, self.value(successor, agentIndex + 1, depthSoFar, alpha, beta))\n",
    "            if x < alpha:\n",
    "                return x\n",
    "            beta = min(beta, x)\n",
    "        return x\n",
    "        \n",
    "    def value(self, gameState, agentIndex, depthSoFar, alpha, beta):\n",
    "        \n",
    "        \"If requisite no. of searches complete, evaluation function\"\n",
    "        if depthSoFar == self.depth or gameState.isWin() or gameState.isLose():\n",
    "            return self.evaluationFunction(gameState)\n",
    "        \"If agentIndex is 0, perform MAX\"\n",
    "        if agentIndex == 0:\n",
    "            return self.MAXvalue(gameState, agentIndex, depthSoFar, alpha, beta)\n",
    "        \"Else (if agentindex > 0), perform MIN\"\n",
    "        if agentIndex > 0:\n",
    "            return self.MINvalue(gameState, agentIndex, depthSoFar, alpha, beta)\n",
    "\n",
    "class ExpectimaxAgent(MultiAgentSearchAgent):\n",
    "    \"\"\"\n",
    "      Your expectimax agent (question 4)\n",
    "    \"\"\"\n",
    "\n",
    "    def getAction(self, gameState):\n",
    "        \"\"\"\n",
    "          Returns the expectimax action using self.depth and self.evaluationFunction\n",
    "\n",
    "          All ghosts should be modeled as choosing uniformly at random from their\n",
    "          legal moves.\n",
    "        \"\"\"\n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        legal = gameState.getLegalActions(0)\n",
    "        successors = [gameState.generateSuccessor(0, action) for action in legal]\n",
    "        maxValue = -float('inf')\n",
    "        goalIndex = 0\n",
    "        for x in range(len(successors)):\n",
    "            actionValue = self.value(successors[x], 1, 0)\n",
    "            if actionValue > maxValue:\n",
    "                maxValue = actionValue\n",
    "                goalIndex = x\n",
    "        \n",
    "        return legal[goalIndex]\n",
    "        \n",
    "    def MAXvalue(self, gameState, agentIndex, depthSoFar):\n",
    "        legal = gameState.getLegalActions(agentIndex)\n",
    "        successors = [gameState.generateSuccessor(agentIndex, action) for action in legal]\n",
    "        x = -float('inf')\n",
    "        for successor in successors:\n",
    "            x = max(x, self.value(successor, 1, depthSoFar))\n",
    "        return x\n",
    "        \n",
    "    def EXPvalue(self, gameState, agentIndex, depthSoFar):\n",
    "        legal = gameState.getLegalActions(agentIndex)\n",
    "        successors = [gameState.generateSuccessor(agentIndex, action) for action in legal]\n",
    "        x = 0.0\n",
    "        for successor in successors:\n",
    "            if agentIndex + 1 == gameState.getNumAgents():\n",
    "                x += self.value(successor, 0, depthSoFar + 1)\n",
    "            else:\n",
    "                x += self.value(successor, agentIndex + 1, depthSoFar)\n",
    "        return x/len(successors)\n",
    "        \n",
    "    def value(self, gameState, agentIndex, depthSoFar):\n",
    "        \n",
    "        \"If requisite no. of searches complete, evaluation function\"\n",
    "        if depthSoFar == self.depth or gameState.isWin() or gameState.isLose():\n",
    "            return self.evaluationFunction(gameState)\n",
    "        \"If agentIndex is 0, perform MAX\"\n",
    "        if agentIndex == 0:\n",
    "            return self.MAXvalue(gameState, agentIndex, depthSoFar)\n",
    "        \"Else (if agentindex > 0), perform EXP\"\n",
    "        if agentIndex > 0:\n",
    "            return self.EXPvalue(gameState, agentIndex, depthSoFar)\n",
    "        \n",
    "def betterEvaluationFunction(currentGameState):\n",
    "    position = currentGameState.getPacmanPosition()\n",
    "    ghostStates = currentGameState.getGhostStates()\n",
    "    scaredTimes = [ghostState.scaredTimer for ghostState in ghostStates] \n",
    "    currentFood = currentGameState.getFood().asList()\n",
    "    \n",
    "    score = float(0)\n",
    "    x, y = position\n",
    "    \n",
    "    # Walls are bad\n",
    "    if currentGameState.hasWall(x, y):\n",
    "        score -= 2\n",
    "    \n",
    "    # Evaluate ghost distances\n",
    "    ghostDistances = [manhattanDistance(position, ghostState.getPosition()) for ghostState in ghostStates]\n",
    "    for distance, scaredTime in zip(ghostDistances, scaredTimes):\n",
    "        if distance <= scaredTime:\n",
    "            # Pacman can eat the ghost\n",
    "            score += 200\n",
    "        else:\n",
    "            # Pacman should avoid ghosts\n",
    "            score -= distance\n",
    "    \n",
    "    # Evaluate distance to nearest food\n",
    "    if currentFood:\n",
    "        nearestFoodDistance = min(manhattanDistance(position, food) for food in currentFood)\n",
    "        score -= nearestFoodDistance\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Abbreviation\n",
    "better = betterEvaluationFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9855137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
