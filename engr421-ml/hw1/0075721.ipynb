{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531e5cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 7)\n",
      "(50000,)\n",
      "(43925, 7)\n",
      "(43925,)\n",
      "[0.0452 0.9548]\n",
      "[[0.32332155 0.64355124 0.09452297 0.56625442 0.68860424 0.08038869\n",
      "  0.16386926]\n",
      " [0.25450318 0.27287198 0.30116873 0.19522872 0.25473358 0.23990449\n",
      "  0.26292309]]\n",
      "[[0.37411661 0.12146643 0.03003534 0.03268551 0.08083039 0.05256184\n",
      "  0.16740283]\n",
      " [0.21979725 0.23401893 0.06516002 0.20605731 0.21215231 0.2476751\n",
      "  0.21724196]]\n",
      "[[0.18727915 0.12014134 0.81713781 0.3745583  0.1139576  0.79416961\n",
      "  0.19699647]\n",
      " [0.24805211 0.24434484 0.26767761 0.3363564  0.22869889 0.23104474\n",
      "  0.23016505]]\n",
      "[[0.11528269 0.11484099 0.05830389 0.02650177 0.11660777 0.07287986\n",
      "  0.47173145]\n",
      " [0.27764745 0.24876424 0.36599363 0.26235757 0.30441521 0.28137567\n",
      "  0.28966991]]\n",
      "[[-15.82088355  -9.34338043]\n",
      " [-16.72418135  -8.90276421]\n",
      " [-17.10744566  -8.8706538 ]\n",
      " ...\n",
      " [-12.64405295  -9.30778786]\n",
      " [-18.11919972  -9.54821295]\n",
      " [-14.6682935   -9.45004023]]\n",
      "[[-16.99824163  -9.95383059]\n",
      " [-13.09696282  -9.42910284]\n",
      " [-12.61174977  -9.54181614]\n",
      " ...\n",
      " [-12.8632337   -9.21878904]\n",
      " [-12.89801912  -9.38543538]\n",
      " [-16.41346909  -9.37469821]]\n",
      "[[ 1066  1194]\n",
      " [  484 47256]]\n",
      "[[  891  1057]\n",
      " [  416 41561]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "X = np.genfromtxt(\"hw01_data_points.csv\", delimiter = \",\", dtype = str)\n",
    "y = np.genfromtxt(\"hw01_class_labels.csv\", delimiter = \",\", dtype = int)\n",
    "\n",
    "\n",
    "\n",
    "# STEP 3\n",
    "# first 50000 data points should be included to train\n",
    "# remaining 43925 data points should be included to test\n",
    "# should return X_train, y_train, X_test, and y_test\n",
    "def train_test_split(X, y):\n",
    "    # your implementation starts below\n",
    "    # Select the first 50000 data points for training\n",
    "    X_train = X[:50000]\n",
    "    y_train = y[:50000]\n",
    "    \n",
    "    # Select the remaining 43925 data points for testing\n",
    "    X_test = X[50000:]\n",
    "    y_test = y[50000:]\n",
    "    # your implementation ends above\n",
    "    return(X_train, y_train, X_test, y_test)\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# STEP 4\n",
    "# assuming that there are K classes\n",
    "# should return a numpy array with shape (K,)\n",
    "def estimate_prior_probabilities(y):\n",
    "    # your implementation starts below\n",
    "    # Count the occurrences of each class\n",
    "    class_counts = np.bincount(y)\n",
    "\n",
    "    # Calculate the total number of data points\n",
    "    total_samples = len(y)\n",
    "\n",
    "    # Calculate the prior probability estimates\n",
    "    class_priors = class_counts / total_samples\n",
    "\n",
    "    # Considering only the last two classes\n",
    "    class_priors = class_priors[-2:]\n",
    "\n",
    "    # your implementation ends above\n",
    "    return class_priors\n",
    "\n",
    "class_priors = estimate_prior_probabilities(y_train)\n",
    "print(class_priors)\n",
    "\n",
    "\n",
    "\n",
    "# STEP 5\n",
    "# assuming that there are K classes and D features\n",
    "# should return four numpy arrays with shape (K, D)\n",
    "def estimate_nucleotide_probabilities(X, y):\n",
    "    # your implementation starts below\n",
    "    num_classes = len(np.unique(y_train))  # Get the number of unique classes\n",
    "    num_positions = X_train.shape[1]  # Get the number of positions in the sequences\n",
    "\n",
    "    # Initialize arrays to store probabilities\n",
    "    pAcd = np.zeros((num_classes, num_positions))\n",
    "    pCcd = np.zeros((num_classes, num_positions))\n",
    "    pGcd = np.zeros((num_classes, num_positions))\n",
    "    pTcd = np.zeros((num_classes, num_positions))\n",
    "\n",
    "    # Calculate probabilities for each class and position\n",
    "    for c in range(num_classes):\n",
    "        # Select data points belonging to class c\n",
    "        X_class_c = X_train[y_train == c + 1]  # Assuming class labels start from 1\n",
    "\n",
    "        # Count occurrences of each nucleotide at each position\n",
    "        total_sequences = len(X_class_c)\n",
    "        total_nucleotides = total_sequences * num_positions\n",
    "\n",
    "        # Calculate conditional probabilities for each nucleotide at each position\n",
    "        pAcd[c] = (np.sum(X_class_c == 'A', axis=0) + 1) / (total_sequences + 4)  # Laplace smoothing\n",
    "        pCcd[c] = (np.sum(X_class_c == 'C', axis=0) + 1) / (total_sequences + 4)\n",
    "        pGcd[c] = (np.sum(X_class_c == 'G', axis=0) + 1) / (total_sequences + 4)\n",
    "        pTcd[c] = (np.sum(X_class_c == 'T', axis=0) + 1) / (total_sequences + 4)\n",
    "    # your implementation ends above\n",
    "    return(pAcd, pCcd, pGcd, pTcd)\n",
    "\n",
    "pAcd, pCcd, pGcd, pTcd = estimate_nucleotide_probabilities(X_train, y_train)\n",
    "print(pAcd)\n",
    "print(pCcd)\n",
    "print(pGcd)\n",
    "print(pTcd)\n",
    "\n",
    "\n",
    "\n",
    "# STEP 6\n",
    "# assuming that there are N data points and K classes\n",
    "# should return a numpy array with shape (N, K)\n",
    "def calculate_score_values(X, pAcd, pCcd, pGcd, pTcd, class_priors):\n",
    "    # your implementation starts below\n",
    "    num_classes, num_positions = pAcd.shape\n",
    "    num_samples = X.shape[0]\n",
    "    \n",
    "    score_values = np.zeros((num_samples, num_classes))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for c in range(num_classes):\n",
    "            # Start with the logarithm of the prior probability of class c\n",
    "            score = np.log(class_priors[c] + np.finfo(float).eps)\n",
    "            \n",
    "            # Add the logarithm of the conditional probability of observing each nucleotide given class c\n",
    "            score += np.sum(np.log([pAcd[c, j] if X[i, j] == 'A' else\n",
    "                                     pCcd[c, j] if X[i, j] == 'C' else\n",
    "                                     pGcd[c, j] if X[i, j] == 'G' else\n",
    "                                     pTcd[c, j] for j in range(num_positions)]))\n",
    "            \n",
    "            score_values[i, c] = score\n",
    "    \n",
    "    # your implementation ends above\n",
    "    return(score_values)\n",
    "\n",
    "scores_train = calculate_score_values(X_train, pAcd, pCcd, pGcd, pTcd, class_priors)\n",
    "print(scores_train)\n",
    "\n",
    "scores_test = calculate_score_values(X_test, pAcd, pCcd, pGcd, pTcd, class_priors)\n",
    "print(scores_test)\n",
    "\n",
    "\n",
    "\n",
    "# STEP 7\n",
    "# assuming that there are K classes\n",
    "# should return a numpy array with shape (K, K)\n",
    "def calculate_confusion_matrix(y_truth, score_values):\n",
    "    # your implementation starts below\n",
    "    num_samples, num_classes = score_values.shape\n",
    "    y_pred = np.argmax(score_values, axis=1) + 1  # Adding 1 to match class labels (assuming class labels start from 1)\n",
    "    \n",
    "    # Initialize confusion matrix\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        true_class = y_truth[i]\n",
    "        predicted_class = y_pred[i]\n",
    "        \n",
    "        # Increment the count in the confusion matrix\n",
    "        confusion_matrix[true_class - 1, predicted_class - 1] += 1\n",
    "    # your implementation ends above\n",
    "    return(confusion_matrix)\n",
    "\n",
    "confusion_train = calculate_confusion_matrix(y_train, scores_train)\n",
    "print(confusion_train)\n",
    "\n",
    "confusion_test = calculate_confusion_matrix(y_test, scores_test)\n",
    "print(confusion_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec025ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
